#!/usr/bin/env python3
import os, json, argparse, numpy as np, pandas as pd, re
import torch
from torch import nn
from torch.utils.data import Dataset, DataLoader

def standardize_columns(df):
    def norm(c):
        c = str(c).strip().lower()
        c = c.replace('\u2009',' ').replace('\u00A0',' ')
        c = c.replace('’',"'").replace('“','"').replace('”','"')
        c = c.replace('%',' pct').replace('²','2')
        c = c.replace('o₂','o2').replace('spo₂','spo2').replace('sao₂','sao2')
        c = re.sub(r'[\s_/]+',' ', c).strip()
        return c
    df = df.copy()
    df.columns = [norm(c) for c in df.columns]
    return df

def load_concat(paths):
    dfs = []
    for p in paths:
        if os.path.exists(p):
            try: df = pd.read_csv(p)
            except: 
                try: df = pd.read_csv(p, sep=';')
                except: df = pd.read_csv(p, sep='\t')
            dfs.append(standardize_columns(df))
    if not dfs: raise SystemExit("No CSVs found.")
    all_cols = sorted(set().union(*[set(d.columns) for d in dfs]))
    dfs = [d.reindex(columns=all_cols) for d in dfs]
    return pd.concat(dfs, axis=0, ignore_index=True)

def seq_data(X, y, lb):
    xs, ys = [], []
    for i in range(lb, len(X)):
        xs.append(X[i-lb:i,:]); ys.append(y[i])
    return np.array(xs), np.array(ys)

def main(a):
    paths = [a.f1,a.f2,a.f3,a.f4,a.f5]
    df = load_concat(paths)

    # Targets: SPO21 & SPO22 -> average
    tnames = [c for c in df.columns if c in ('spo21','spo22')]
    if not tnames: raise SystemExit("未找到 SPO21 / SPO22。")
    y = df[tnames].apply(pd.to_numeric, errors='coerce').mean(axis=1).ffill().bfill()

    # Preferred features
    pref = ['pulse 1','pulse 2','pulse 3','pulse 4','pulse 5',
            'pi 1','pi 2','pi 3','pi 4','pi 5',
            'red drv 1','ir drv 1','dc gain 1','ac gain 1',
            'red drv 2','ir drv 2','dc gain 2','ac gain 2',
            'red drv 3','ir drv 3','dc gain 3','ac gain 3',
            'red drv 4','ir drv 4','dc gain 4','ac gain 4',
            'red drv 5','ir drv 5','dc gain 5','ac gain 5',
            'ecg 3','fio2 3','etco2 pct 3','etco2 mmhg 3','rr co2 3','rr ecg 3',
            'insp tv 3','exp tv 3','rig fio2']
    avail = [c for c in pref if c in df.columns]
    if len(avail) < 5:
        num_all = df.apply(pd.to_numeric, errors='coerce')
        feat_cols = [c for c in num_all.columns if c not in tnames]
    else:
        feat_cols = avail

    X = df[feat_cols].apply(pd.to_numeric, errors='coerce').ffill().bfill()

    # 时间切分
    n = len(X); n_tr = int(0.7*n); n_va = int(0.15*n)
    a1,b1 = 0, n_tr; a2,b2 = b1, b1+n_va; a3,b3 = b2, n
    Xtr_raw, Xva_raw, Xte_raw = X.iloc[a1:b1].to_numpy(), X.iloc[a2:b2].to_numpy(), X.iloc[a3:b3].to_numpy()
    ytr_raw, yva_raw, yte_raw = y.iloc[a1:b1].to_numpy(), y.iloc[a2:b2].to_numpy(), y.iloc[a3:b3].to_numpy()

    # 标准化（按训练集）
    mu = Xtr_raw.mean(axis=0, keepdims=True)
    sigma = Xtr_raw.std(axis=0, keepdims=True) + 1e-8
    Xtr = (Xtr_raw-mu)/sigma; Xva = (Xva_raw-mu)/sigma; Xte = (Xte_raw-mu)/sigma

    # 构造序列
    lb = a.lookback
    Xtr, ytr = seq_data(Xtr, ytr_raw, lb)
    Xva, yva = seq_data(Xva, yva_raw, lb)
    Xte, yte = seq_data(Xte, yte_raw, lb)

    # 数据集 & 模型
    class DS(Dataset):
        def __init__(self,X,y): self.X=torch.tensor(X,dtype=torch.float32); self.y=torch.tensor(y,dtype=torch.float32).view(-1,1)
        def __len__(self): return len(self.X)
        def __getitem__(self,i): return self.X[i], self.y[i]

    class LSTMReg(nn.Module):
        def __init__(self, in_dim):
            super().__init__()
            self.lstm = nn.LSTM(input_size=in_dim, hidden_size=64, batch_first=True)
            self.drop = nn.Dropout(0.2)
            self.fc1 = nn.Linear(64,32)
            self.relu = nn.ReLU()
            self.out = nn.Linear(32,1)
        def forward(self,x):
            o,_ = self.lstm(x); o = o[:,-1,:]
            o = self.drop(o); o = self.relu(self.fc1(o)); return self.out(o)

    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    model = LSTMReg(Xtr.shape[2]).to(device)
    opt = torch.optim.Adam(model.parameters(), lr=a.lr)
    loss_fn = nn.L1Loss()

    dl_tr = DataLoader(DS(Xtr,ytr), batch_size=a.batch_size, shuffle=True)
    best, wait, patience = 1e9, 0, 5
    os.makedirs(a.outdir, exist_ok=True)

    for epoch in range(a.epochs):
        model.train()
        for xb,yb in dl_tr:
            xb,yb = xb.to(device), yb.to(device)
            opt.zero_grad(); loss = loss_fn(model(xb), yb); loss.backward(); opt.step()
        # 验证
        model.eval()
        with torch.no_grad():
            xv = torch.tensor(Xva,dtype=torch.float32).to(device)
            yv = torch.tensor(yva,dtype=torch.float32).view(-1,1).to(device)
            v = loss_fn(model(xv), yv).item()
        if v < best - 1e-6:
            best, wait = v, 0
            torch.save(model.state_dict(), os.path.join(a.outdir,"lstm_best.pt"))
            np.save(os.path.join(a.outdir,"mu.npy"), mu)
            np.save(os.path.join(a.outdir,"sigma.npy"), sigma)
            with open(os.path.join(a.outdir,"meta.json"),"w") as f:
                json.dump({"features": feat_cols, "lookback": lb, "targets": tnames}, f, indent=2)
        else:
            wait += 1
            if wait >= patience: break

    # 测试评估
    model.load_state_dict(torch.load(os.path.join(a.outdir,"lstm_best.pt"), map_location=device))
    model.eval()
    with torch.no_grad():
        yt = model(torch.tensor(Xte,dtype=torch.float32).to(device)).cpu().numpy().reshape(-1)
    y_true = yte.reshape(-1)
    mae = float(np.mean(np.abs(yt - y_true)))
    rmse = float(np.sqrt(np.mean((yt - y_true)**2)))
    ss_res = float(np.sum((y_true - yt)**2))
    ss_tot = float(np.sum((y_true - np.mean(y_true))**2))+1e-8
    r2 = float(1.0 - ss_res/ss_tot)
    print(json.dumps({"MAE":mae,"RMSE":rmse,"R2":r2,"saved_to":a.outdir}, indent=2))

if __name__ == "__main__":
    p = argparse.ArgumentParser()
    p.add_argument("--f1", default="100001.csv"); p.add_argument("--f2", default="100002.csv")
    p.add_argument("--f3", default="100003.csv"); p.add_argument("--f4", default="100004.csv")
    p.add_argument("--f5", default="100005.csv")
    p.add_argument("--lookback", type=int, default=60)
    p.add_argument("--epochs", type=int, default=30)
    p.add_argument("--batch_size", type=int, default=256)
    p.add_argument("--lr", type=float, default=1e-3)
    p.add_argument("--outdir", default="spo2_rnn_torch_out")
    main(p.parse_args())
