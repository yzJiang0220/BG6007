

import numpy as np
import matplotlib.pyplot as plt
import cv2
from scipy.signal import butter, filtfilt, find_peaks

class PPG_Data:
    """
    This class is a direct adaptation of the PPG_Data class from the official repository's data_loader.py.
    It's modified to load data from a video file instead of a pre-processed .mat file.
    """
    def __init__(self, video_path, sig_length=90):
        self.sig_length = sig_length
        self.video_path = video_path

        # --- MODIFICATION START ---
        # The original code loaded a .mat file here.
        # We replace that logic with a function to extract signals from a video.
        self._load_from_video()
        # --- MODIFICATION END ---

    def _load_from_video(self):
        """
        A new private method to handle video processing. It populates the same
        instance variables (self.wave, self.time, etc.) as the original code.
        """
        cap = cv2.VideoCapture(self.video_path)
        if not cap.isOpened():
            raise IOError(f"Cannot open video file: {self.video_path}")

        self.fs = cap.get(cv2.CAP_PROP_FPS)
        if self.fs == 0:
            print("Warning: FPS is 0. Defaulting to 30.")
            self.fs = 30

        # The 'wave' variable in the original .mat file stores R, G, B signals.
        # We will create it from the video.
        r_signal, g_signal, b_signal = [], [], []
        
        while True:
            ret, frame = cap.read()
            if not ret:
                break
            
            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            r_signal.append(np.mean(frame_rgb[:, :, 0]))
            g_signal.append(np.mean(frame_rgb[:, :, 1]))
            b_signal.append(np.mean(frame_rgb[:, :, 2]))
        
        cap.release()

        # The original 'wave' is a (3, N) numpy array. We replicate that structure.
        self.wave = np.array([r_signal, g_signal, b_signal])
        
        # Create a time vector, similar to the original data structure.
        self.time = np.arange(self.wave.shape[1]) / self.fs
        
        # Ground truth SpO2 is not available in a new video.
        self.gt_spo2 = np.array([])
        # Subject ID is not applicable.
        self.sub_id = "N/A"

    def __len__(self):
        # This remains unchanged from the original repository code.
        return self.wave.shape[1] - self.sig_length + 1

    def __getitem__(self, idx):
        # This remains unchanged, returning a window of the signal.
        return self.wave[:, idx:idx + self.sig_length]

class SpO2Estimator:
    """
    This is a supplementary class to provide the SpO2 estimation logic,
    which replaces the unavailable deep learning model from the paper.
    """
    def __init__(self, wave, fs):
        self.wave = wave # Expects a (3, N) numpy array [R, G, B]
        self.fs = fs

    def estimate(self):
        r_signal = self.wave[0, :]
        b_signal = self.wave[2, :]

        # 1. Filter signals to get AC components
        nyquist = 0.5 * self.fs
        low = 0.67 / nyquist
        high = 4.0 / nyquist
        b, a = butter(1, [low, high], btype='band')
        r_ac = filtfilt(b, a, r_signal)
        b_ac = filtfilt(b, a, b_signal)

        # 2. Get DC components
        r_dc = np.mean(r_signal)
        b_dc = np.mean(b_signal)

        # 3. Calculate "Ratio of Ratios"
        R = (np.std(r_ac) / r_dc) / (np.std(b_ac) / b_dc)

        # 4. Apply empirical formula
        spo2 = 110 - 25 * R
        spo2 = max(80, min(99.9, spo2)) # Clamp to plausible range

        # 5. Estimate heart rate for reference
        peaks, _ = find_peaks(r_ac, height=np.std(r_ac), distance=self.fs/4)
        if len(peaks) < 2:
            hr = "N/A"
        else:
            hr = 60.0 / (np.mean(np.diff(peaks)) / self.fs)
            
        return spo2, hr

def main():
    # --- User Configuration ---
    # IMPORTANT: Replace this with the path to your fingertip video file.
    video_path = ("100001.mp4")
    # --------------------------

    # 1. Load data using the adapted PPG_Data class (faithful to data_loader.py)
    print(f"Loading data from video: {video_path}")
    ppg_data = PPG_Data(video_path=video_path)
    print(f"Data loaded. Found {ppg_data.wave.shape[1]} frames at {ppg_data.fs:.2f} FPS.")

    # 2. Estimate SpO2 using the supplementary estimator class
    estimator = SpO2Estimator(ppg_data.wave, ppg_data.fs)
    spo2_est, hr_est = estimator.estimate()

    print("\n--- Estimation Results ---")
    if isinstance(hr_est, str):
        print(f"Estimated Heart Rate: {hr_est}")
    else:
        print(f"Estimated Heart Rate: {hr_est:.2f} BPM")
    print(f"Estimated SpO2 (overall): {spo2_est:.2f} %")
    print("--------------------------\n")

    # 3. Visualize the signals (faithful to visualize.py)
    print("Generating plot...")
    r, g, b = ppg_data.wave[0], ppg_data.wave[1], ppg_data.wave[2]
    
    plt.figure(figsize=(15, 5))
    plt.plot(ppg_data.time, r, 'r', label='Red Channel')
    plt.plot(ppg_data.time, g, 'g', label='Green Channel')
    plt.plot(ppg_data.time, b, 'b', label='Blue Channel')
    plt.title('Extracted PPG Signals from Video')
    plt.xlabel('Time (s)')
    plt.ylabel('Mean Pixel Intensity')
    plt.legend()
    plt.grid(True)
    plt.savefig("ppg_signals_from_video.png")
    print("Plot saved to ppg_signals_from_video.png")

if __name__ == "__main__":
    main()
